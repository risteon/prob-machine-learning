{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "from numpy.random import multivariate_normal\n",
    "from scipy.linalg import cho_factor, cho_solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# colors:\n",
    "dark = np.array([51.0, 51.0, 51.0]) / 255.0\n",
    "red = np.array([141.0, 45.0, 57.0]) / 255.0\n",
    "gold = np.array([174.0, 159.0, 109.0]) / 255.0\n",
    "gray = np.array([175.0, 179.0, 183.0]) / 255.0\n",
    "lred = np.array([1, 1, 1]) - 0.5 * (np.array([1, 1, 1]) - red)\n",
    "lgold = np.array([1, 1, 1]) - 0.5 * (np.array([1, 1, 1]) - gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian inference on linear functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(a):  # phi(a) = [1,a,a^2]\n",
    "    return np.power(a, range(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some other options for the feature functions to try. Try around! Try scaling and changing the prior and/or the features (note that there are a few degrees of freedom shared between them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(a):\n",
    "    # linear\n",
    "    return 1 * (np.abs(a - np.linspace(-8, 8, 8).T)) - np.linspace(-8, 8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(a):\n",
    "    return 2 * (a > np.linspace(-8, 8, 8).T)  # steps that switch on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def phi(a):  # steps that change sign\n",
    "    return 2 * ((a > np.linspace(-8, 8, 8).T) - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def phi(a):\n",
    "    # linear\n",
    "    return 1 * (np.abs(a - np.linspace(-8, 8, 8).T) - np.linspace(-8, 8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def phi(a):\n",
    "    # ReLU: \n",
    "    F = 265\n",
    "    return 1 * (a - np.linspace(-8.1, 8, F).T) * (a > np.linspace(-8.1, 8, F).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def phi(a):  # Fourier features\n",
    "    return 3 * np.hstack((np.sin(a * np.arange(4)), np.cos(a * np.arange(4))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def phi(a):\n",
    "    return 5 * np.exp(\n",
    "        -((a - np.linspace(-8, 8, 12).T) ** 2) / 2.0 / 0.5 ** 2\n",
    "    )  # Gaussian / RBF / SE features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(a):  # \"Eiffel towers\"\n",
    "    return 5 * np.exp(-np.abs(a - np.linspace(-8, 8, 12).T) / 1 ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" ==== PARAMETRIC GAUSSIAN REGRESSION IN PYTHON ====\n",
    "    this is didactic code. \n",
    "    In practice, you can and should obviously write this \n",
    "    in a more re-usable (be it functional or object-oriented) \n",
    "    style. The point is to show that everything here involves\n",
    "    simple low-level operations (at most, numpy.linalg). There \n",
    "    is no \"deep learning package\" here, and no stochastic optimizer. \n",
    "\"\"\"\n",
    "# first, define the prior\n",
    "F = len(phi(0))  # number of features\n",
    "# set parameters of prior on the weights\n",
    "mu = np.zeros((F, 1))\n",
    "Sigma = 10 * np.eye(F) / F  # p(w)=N(mu,Sigma)\n",
    "\n",
    "# construct implied prior on f_x\n",
    "n = 100  # number of grid-points, for plotting\n",
    "x = np.linspace(-8, 8, n)[:, np.newaxis]  # reshape is needed for phi to work\n",
    "m = phi(x) @ mu\n",
    "kxx = phi(x) @ Sigma @ phi(x).T  # p(f_x)=N(m,k_xx)\n",
    "s = multivariate_normal(m.flatten(), kxx + 1e-6 * np.eye(n), size=5).T\n",
    "stdpi = np.sqrt(np.diag(kxx))[:, np.newaxis]  # marginal stddev, for plotting\n",
    "\n",
    "# then, load data from disk\n",
    "data = scipy.io.loadmat(\"07.1_lindata.mat\")\n",
    "# import scipy.io; data = scipy.io.loadmat('nlindata.mat') # use this line to get the nonlinear data.\n",
    "X = data[\"X\"]  # inputs\n",
    "Y = data[\"Y\"]  # outputs\n",
    "sigma = float(data[\"sigma\"])  # measurement noise std-deviation\n",
    "N = len(X)  # number of data\n",
    "\n",
    "# evidence: p(Y) = N(Y;M,kXX + sigma**2 * no.eye(N))\n",
    "M = phi(X) @ mu\n",
    "kXX = phi(X) @ Sigma @ phi(X).T  # p(f_X) = N(M,k_XX)\n",
    "G = kXX + sigma ** 2 * np.eye(N)\n",
    "\n",
    "# now, do inference (i.e. construct the posterior)\n",
    "# the following in-place decomposition is the most expensive step at O(N^3):\n",
    "G = cho_factor(G)\n",
    "kxX = phi(x) @ Sigma @ phi(X).T  # Cov(f_x,f_X) = k_xX\n",
    "A = cho_solve(G, kxX.T).T  # pre-compute for re-use (but is only O(N^2))\n",
    "\n",
    "# # posterior p(f_x|Y) = N(f_x,mpost,vpost)\n",
    "mpost = m + A @ (Y - M)  # mean\n",
    "vpost = kxx - A @ kxX.T  # covariance\n",
    "spost = multivariate_normal(mpost.flatten(), vpost  + 1e-6 * np.eye(n), size=5).T  # samples\n",
    "stdpo = np.sqrt(np.diag(vpost))[:, np.newaxis]  # marginal stddev, for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (25, 10)\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "\n",
    "def GaussPDFscaled(y, m, s):  # shading\n",
    "    return np.exp(-0.5 * (y - m.T) ** 2 / (s ** 2).T)\n",
    "\n",
    "\n",
    "yy = np.linspace(-15, 20, 200).reshape([200, 1])\n",
    "P = GaussPDFscaled(yy, m, stdpi)\n",
    "\n",
    "ax[0].imshow(\n",
    "    P, extent=[-8, 8, -15, 20], aspect=\"auto\", origin=\"lower\", cmap=\"Greys\", alpha=0.4\n",
    ")\n",
    "ax[0].plot(x, phi(x), \"-\", color=gray)\n",
    "ax[0].plot(x, s, \":\", color=red)  # prior\n",
    "ax[0].plot(x, m, \"-\", color=red)\n",
    "ax[0].plot(x, m + 2 * stdpi, \"-\", color=lred)\n",
    "ax[0].plot(x, m - 2 * stdpi, \"-\", color=lred)\n",
    "ax[0].set(xlim=[-8, 8], ylim=[-15, 20], title=\"prior\")\n",
    "\n",
    "Ppost = GaussPDFscaled(yy, mpost, stdpo)  # shading by local marginal pdf\n",
    "ax[1].imshow(\n",
    "    Ppost,\n",
    "    extent=[-8, 8, -15, 20],\n",
    "    aspect=\"auto\",\n",
    "    origin=\"lower\",\n",
    "    cmap=\"Greys\",\n",
    "    alpha=0.4,\n",
    ")\n",
    "# Errorbar does not work? Broadcast error?\n",
    "#ax[1].errorbar(X, Y, yerr=sigma, fmt=\"ok\")  # data\n",
    "ax[1].errorbar(X, Y, fmt=\"ok\")  # data\n",
    "ax[1].plot(x, mpost, \"-\", color=red)  # posterior mean\n",
    "ax[1].plot(x, mpost + 2 * stdpo, \"-\", color=lred)  # upper error bars on f\n",
    "ax[1].plot(x, mpost - 2 * stdpo, \"-\", color=lred)  # lower error bars on f\n",
    "\n",
    "ax[1].plot(\n",
    "    x, mpost + 2 * stdpo + 2 * sigma, \"-\", color=gold\n",
    ")  # predictive error bars (on y)\n",
    "ax[1].plot(x, mpost - 2 * stdpo - 2 * sigma, \"-\", color=gold)\n",
    "\n",
    "ax[1].plot(x, spost, \":\", color=red)  # samples\n",
    "ax[1].set(xlim=[-8, 8], ylim=[-15, 20], title=\"posterior\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
